{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_K6mU4FglA4J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-31 17:58:35.329431: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Hkw3cF_Zkhe2"
   },
   "outputs": [],
   "source": [
    "def make_predictions(model, tokenizer, input_text, prompt, device, encoding=\"utf-8\"):\n",
    "    predictions = []\n",
    "    for line in input_text:\n",
    "        inputs = tokenizer.encode(prompt + line, return_tensors=\"pt\").to(device)\n",
    "        outputs = model.generate(inputs)\n",
    "        prediction = tokenizer.decode(outputs[0])\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "C8w0OQ5Ymnrs"
   },
   "outputs": [],
   "source": [
    "def format_predictions(predictions_text):\n",
    "\n",
    "    extracted_lines = [line[line.find('<pad>') + 5 : line.find('</s>')].strip() for line in predictions_text]\n",
    "\n",
    "    return extracted_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tFJFchd4nihW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "def calculate_accuracy(predictions, target):\n",
    "\n",
    "    labels = [line.strip() for line in target]\n",
    "\n",
    "    predictions = [line.strip() for line in predictions]\n",
    "\n",
    "    # Compare the predictions with the actual labels and calculate the accuracy\n",
    "    print(classification_report(labels, predictions))\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy * 100}%\")\n",
    "    print(f\"Macro F1 score: {f1_score(labels, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HUOFDtWUjdBS"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"NLP_ass_test.tsv\", sep=\"\\t\", names=[\"text\", \"label\"])\n",
    "\n",
    "test_text = df_test[\"text\"].values.tolist()\n",
    "test_labels = df_test[\"label\"].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngUqknaSj_gu"
   },
   "source": [
    "# Zero shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BZnbOD9JjfZm"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f2b54a2bf74bb9ae4aec915879aee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99778d8084c1441baf8203978b5188ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbf871be6314c2bbd6086be2b9ffd60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e083e2ab3aa144dd9eeb54bb4a2bee63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfbe0f86d9a41e19e83af403722c3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40582d4c1bb3447bb2c945ff925fd165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b78eea64e0430ea45d38728aefb335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c08031dbcce4cbb824f5372e813bd7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a11fa3970b49b697a33a8989864af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2852e9c9e2747c2bf392fca9643decc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5bcddf91993400ab6e63e2bd2ddd39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b74510f1ab44569c89f3f4b2f47b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a808ae27cc554650aeb5e7f66104d7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3bba86aeeca4d52ad425291851a6dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the FLAN T5 model and tokenizer\n",
    "tokenizer_base = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model_base = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "tokenizer_small = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "model_small = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model_base.to(device)\n",
    "model_small.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTS1bgSUj2Sv"
   },
   "source": [
    "## FLAN T5 Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "2ZcYZ94aUmXS",
    "outputId": "8a4d95df-2e77-4455-d40d-52635ba852ba"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"classify the following comment in to either \"hatespeech\", or \"offensive\" or \"normal\" ONLY : \"\"\"\n",
    "\n",
    "predictions_zero_base = make_predictions(model_base, tokenizer_base, test_text, prompt, device)\n",
    "\n",
    "predictions_zero_base = format_predictions(predictions_zero_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Gt_tLVbIviQ8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.51      0.64      0.56       594\n",
      "      normal       0.58      0.64      0.61       782\n",
      "   offensive       0.33      0.19      0.24       548\n",
      "\n",
      "    accuracy                           0.51      1924\n",
      "   macro avg       0.47      0.49      0.47      1924\n",
      "weighted avg       0.49      0.51      0.49      1924\n",
      "\n",
      "Accuracy: 51.03950103950103%\n",
      "Macro F1 score: 0.4700227612620078\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "def calculate_accuracy(predictions, target):\n",
    "\n",
    "    labels = [line.strip() for line in target]\n",
    "\n",
    "    predictions = [line.strip() for line in predictions]\n",
    "\n",
    "    # Compare the predictions with the actual labels and calculate the accuracy\n",
    "    print(classification_report(labels, predictions))\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy * 100}%\")\n",
    "    print(f\"Macro F1 score: {f1_score(labels, predictions, average='macro')}\")\n",
    "calculate_accuracy(predictions_zero_base, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KG9OS40FkUkx"
   },
   "source": [
    "## FLAN T5 small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wMfLf65gv2Ol"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"classify the following comment in to either \"hatespeech\", or \"offensive\" or \"normal\" : \"\"\"\n",
    "\n",
    "predictions_zero_small = make_predictions(model_small, tokenizer_small, test_text, prompt, device)\n",
    "\n",
    "predictions_zero_small = format_predictions(predictions_zero_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qdcW6qTtyh4z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      acceptable       0.00      0.00      0.00         0\n",
      "    anti semitic       0.00      0.00      0.00         0\n",
      "      hatespeech       0.25      0.01      0.01       594\n",
      "      hypocrites       0.00      0.00      0.00         0\n",
      "        nonsense       0.00      0.00      0.00         0\n",
      "          normal       0.50      0.01      0.01       782\n",
      "       offensive       0.29      0.99      0.45       548\n",
      "      stereotype       0.00      0.00      0.00         0\n",
      "stereotypespeech       0.00      0.00      0.00         0\n",
      "unpopularopinion       0.00      0.00      0.00         0\n",
      "     unrepentant       0.00      0.00      0.00         0\n",
      "\n",
      "        accuracy                           0.29      1924\n",
      "       macro avg       0.09      0.09      0.04      1924\n",
      "    weighted avg       0.36      0.29      0.14      1924\n",
      "\n",
      "Accuracy: 28.586278586278585%\n",
      "Macro F1 score: 0.042534971731280846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/miniconda3/envs/nlp-a2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tony/miniconda3/envs/nlp-a2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tony/miniconda3/envs/nlp-a2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(predictions_zero_small, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATRcq1cp59-H"
   },
   "source": [
    "# Few shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOMI6_5A6EVO"
   },
   "source": [
    "## FLAN T5 base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "C1aKyqq06BSz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Hatespeech is defined as sentences that attack or degrade a person or group on the basis of attributes such as race, religion, ethnic origin, national origin, sex, disability, sexual orientation, or gender identity. Normal sentences describe everyday occurrences, opinions, beliefs, or feelings without attacking or degrading others. Offensive sentences contain profanity, insults, or negative statements intended to offend, but not specifically targeting protected groups or containing threats.\n",
    "\n",
    "Classify the following sentence into either 'hatespeech' or 'offensive' or 'normal':\n",
    "\n",
    "'Today is a nice day': 'normal'\n",
    "'You are stupid': 'offensive'\n",
    "'I don't like green cars': 'normal'\n",
    "'Fuck you, idiot': 'offensive'\n",
    "'a negro moslem doctor got struck off for negligence when a white <number> year old kid with down syndrome died the guardians response is to help promote a crowd funding campaign for her': 'hatespeech'\n",
    "'anyway princess sapphire of silverland is a dyke and threw the first brick at stonewall': 'offensive'\n",
    "'if we could teach a giraffe to paint that would be one handy sumbitch': 'normal'\n",
    "'she wanna meet carti that bitch is a barbie 🦋': 'normal'\n",
    "'smiling cuz i am young black rich and i am handsome': 'normal'\n",
    "'bitches be so fine and got the nerve to like niggas 😒': 'offensive'\n",
    "\n",
    "Sentence: \"\"\"\n",
    "\n",
    "predictions_few_base = make_predictions(model_base, tokenizer_base, test_text, prompt, device)\n",
    "\n",
    "predictions_few_base = format_predictions(predictions_few_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "waSz0GPz8PLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.67      0.35      0.46       594\n",
      "      normal       0.50      0.83      0.62       782\n",
      "   offensive       0.39      0.21      0.27       548\n",
      "\n",
      "    accuracy                           0.51      1924\n",
      "   macro avg       0.52      0.46      0.45      1924\n",
      "weighted avg       0.52      0.51      0.47      1924\n",
      "\n",
      "Accuracy: 50.67567567567568%\n",
      "Macro F1 score: 0.45122897067014717\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(predictions_few_base, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVRvoT5gsx9m"
   },
   "source": [
    "## FLAN T5 small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4gxyQW20B6sV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Hatespeech is defined as sentences that attack or degrade a person or group on the basis of attributes such as race, religion, ethnic origin, national origin, sex, disability, sexual orientation, or gender identity. Normal sentences describe everyday occurrences, opinions, beliefs, or feelings without attacking or degrading others. Offensive sentences contain profanity, insults, or negative statements intended to offend, but not specifically targeting protected groups or containing threats.\n",
    "\n",
    "Classify the following sentence into either 'hatespeech' or 'offensive' or 'normal':\n",
    "\n",
    "'Today is a nice day': 'normal'\n",
    "'You are stupid': 'offensive'\n",
    "'I don't like green cars': 'normal'\n",
    "'Fuck you, idiot': 'offensive'\n",
    "'a negro moslem doctor got struck off for negligence when a white <number> year old kid with down syndrome died the guardians response is to help promote a crowd funding campaign for her': 'hatespeech'\n",
    "'anyway princess sapphire of silverland is a dyke and threw the first brick at stonewall': 'offensive'\n",
    "'if we could teach a giraffe to paint that would be one handy sumbitch': 'normal'\n",
    "'she wanna meet carti that bitch is a barbie 🦋': 'normal'\n",
    "'smiling cuz i am young black rich and i am handsome': 'normal'\n",
    "'bitches be so fine and got the nerve to like niggas 😒': 'offensive'\n",
    "\n",
    "Sentence: \"\"\"\n",
    "\n",
    "predictions_few_small = make_predictions(model_small, tokenizer_small, test_text, prompt, device)\n",
    "\n",
    "predictions_few_small = format_predictions(predictions_few_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FryFMVULCEH2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  acceptable       0.00      0.00      0.00         0\n",
      "  hatespeech       0.00      0.00      0.00       594\n",
      "      normal       0.00      0.00      0.00       782\n",
      "   offensive       0.29      1.00      0.44       548\n",
      "   unnatural       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.28      1924\n",
      "   macro avg       0.06      0.20      0.09      1924\n",
      "weighted avg       0.08      0.28      0.13      1924\n",
      "\n",
      "Accuracy: 28.482328482328484%\n",
      "Macro F1 score: 0.08874493927125507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/miniconda3/envs/nlp-a2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tony/miniconda3/envs/nlp-a2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tony/miniconda3/envs/nlp-a2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tony/miniconda3/envs/nlp-a2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tony/miniconda3/envs/nlp-a2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tony/miniconda3/envs/nlp-a2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions_few_small = make_predictions(model_small, tokenizer_small, test_text, prompt, device)\n",
    "\n",
    "predictions_few_small = format_predictions(predictions_few_small)\n",
    "\n",
    "calculate_accuracy(predictions_few_small, test_labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp-a2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
